from fastapi import APIRouter, HTTPException, BackgroundTasks
from pydantic import BaseModel
from typing import List, Optional
from backend.ai_engine.llm import get_llm_provider

router = APIRouter()
llm = get_llm_provider()

class CourseGenerationRequest(BaseModel):
    topic: str
    level: str = "Beginning"
    modules: int = 4

class CourseGenerationResponse(BaseModel):
    title: str
    description: str
    outline: List[str]

@router.post("/generate-course", response_model=CourseGenerationResponse)
async def generate_course(request: CourseGenerationRequest):
    """
    Generate a course outline using local Ollama instance.
    """
    system_prompt = "You are an expert curriculum designer. Create a structured course outline."
    user_prompt = f"""
    Create a {request.level} level course about "{request.topic}".
    The course should have exactly {request.modules} modules.
    
    Return the response in strictly valid JSON format with the following structure:
    {{
        "title": "Course Title",
        "description": "Brief summary of the course",
        "outline": [
            "Module 1: Title - Brief Description",
            "Module 2: Title - Brief Description",
            ...
        ]
    }}
    Do not include any explanation, only the JSON.
    """
    
    try:
        raw_response = llm.generate(user_prompt, system_prompt)
        
        # Simple cleanup if the model adds markdown code blocks
        clean_response = raw_response.replace("```json", "").replace("```", "").strip()
        
        import json
        data = json.loads(clean_response)
        
        return CourseGenerationResponse(
            title=data.get("title", f"Course on {request.topic}"),
            description=data.get("description", "Generated by AI"),
            outline=data.get("outline", [])
        )
        
    except Exception as e:
        print(f"Generation Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))
